<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quantum Finance</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/recorderjs/0.1.0/recorder.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.5.4/socket.io.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Montserrat', sans-serif;
            background-color: #f0f8ff;
            color: #333;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            flex-direction: column;
        }

        /* Estilo para a div que ocupa toda a página */
        #start-attendance {
            background-color: #01134d;
            color: white;
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            transition: background-color 0.3s ease;
            text-align: center;
        }

        /* Efeito ao passar o mouse (hover) */
        #start-attendance:hover {
            background-color: #1e40af;
        }

        /* Estilo para a imagem centralizada */
        #start-attendance img {
            width: 150px; /* Tamanho da imagem */
            height: auto;
        }

        /* Estilo para o texto abaixo da imagem */
        #start-attendance p {
            font-size: 11px;
            padding: 15px;  /* Espaço interno dentro da caixa */
            margin-top: 20px; /* Se quiser algum espaço externo */
            border: 0px solid #01134d; /* Borda ao redor da caixa */
            border-radius: 8px; /* Bordas arredondadas */
            width: 25%; /* Ajuste a largura da caixa conforme necessário */
            text-align: center; /* Ajuste o alinhamento do texto, se necessário */
        }

        #pulse-indicator {
            display: none;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
        }

        #pulse-indicator img {
            width: 200px;
            height: auto;
        }

        #mic-indicator {
            display: none;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            animation: pulse-animation 1.5s infinite;
        }

        #mic-indicator img {
            width: 100px;
            height: auto;
        }

        #loading-indicator {
            display: none;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            animation: pulse-animation 1.5s infinite;
        }

        #loading-indicator img {
            width: 100px;
            height: auto;
        }

        @keyframes pulse-animation {
            0% { transform: translate(-50%, -50%) scale(1); opacity: 1; }
            50% { transform: translate(-50%, -50%) scale(1.15); opacity: 0.7; }
            100% { transform: translate(-50%, -50%) scale(1); opacity: 1; }
        }
    </style>
</head>
<body>

    <!-- Div that takes up the whole page with the image and text -->
    <div id="start-attendance" onclick="startAttendance()">
        <img src="{{ url_for('static', filename='images/white_logo.png') }}" alt="white_logo">
        <h1>Atendimento Digital</h1>
        <h2>Clique para começar</h2>
        <p>
            Essa é a entrega para a avaliação da disciplina Audio Recognition, ministrada pelo professor Alexandre Gastaldi do curso de MBA Data Science e Artificial Intelligence da FIAP. <br><br>
            Turma: 7DTSR <br>
            Eduardo Manrique - 354953 <br>
            Enzo Bernardi - 354915 <br>
            Fabian Bram - 354914
        </p>
    </div>

    <div id="pulse-indicator">
        <img src="{{ url_for('static', filename='images/logo.png') }}" alt="Logo">
    </div>

    <div id="mic-indicator">
        <img src="{{ url_for('static', filename='images/mic.png') }}" alt="Microfone">
    </div>

    <div id="loading-indicator">
        <img src="{{ url_for('static', filename='images/loading.png') }}" alt="Loading">
    </div>

    <script>
        let recorder;
        let audioStream;
        const pulseIndicator = document.getElementById("pulse-indicator");
        const micIndicator = document.getElementById("mic-indicator");
        const loadingIndicator = document.getElementById("loading-indicator");
        const startAttendanceDiv = document.getElementById("start-attendance");

        const socket = io.connect();

        socket.on('message_from_server', (data) => {
            const { texto, trigger_record } = data;
            speak(texto, trigger_record);
        });

        // Start attendance function that hides the div and starts the process
        function startAttendance() {
            // Hide the "Start attendance" div when clicked
            startAttendanceDiv.style.display = "none";

            // Calls the "speak" function when the div is clicked
            const trigger_record = { seconds: 5, option: 1 };  // Example structure
            speak('Bem-vindo ao atendimento digital da Quantum Finance! Escolha uma das opções: (1) Consulta ao saldo da conta, (2) Simulação de compra internacional, (3) Falar com um atendente, (4) Sair do atendimento', trigger_record);
        }

        function record(trigger_record) {
            const { seconds, option } = trigger_record;

            // If seconds or option is zero or invalid, don't record
            if (seconds <= 0) return;

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioStream = stream;
                    let audioContext = new AudioContext();
                    let input = audioContext.createMediaStreamSource(stream);
                    recorder = new Recorder(input);
                    recorder.record();

                    micIndicator.style.display = "block";

                    setTimeout(() => {
                        stopRecording(option);
                    }, seconds * 1000);  // Convert seconds to milliseconds
                })
                .catch(err => console.error("Erro ao acessar microfone:", err));
        }

        function stopRecording(option) {
            recorder.stop();
            audioStream.getTracks().forEach(track => track.stop());

            micIndicator.style.display = "none";

            recorder.exportWAV(blob => {
                let reader = new FileReader();
                reader.readAsDataURL(blob);
                reader.onloadend = function() {
                    let base64data = reader.result.split(',')[1];
                    sendAudio(base64data, option);
                };
            });
        }

        function sendAudio(audioBase64, option) {
            loadingIndicator.style.display = "block";

            fetch('/recognize', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ audio_bytes: audioBase64, option: option })
            })
            .then(response => response.json())
            .then(data => {
                console.log("Áudio reconhecido:", data);
                loadingIndicator.style.display = "none";
            })
            .catch(error => {
                console.error("Erro ao enviar áudio:", error);
                loadingIndicator.style.display = "none";
            });
        }

        function speak(texto, trigger_record) {
            fetch('/speak', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ texto: texto, trigger_record: trigger_record })
            })
            .then(response => response.json())
            .then(data => {
                if (data.audio_bytes) {
                    const audio = new Audio("data:audio/wav;base64," + data.audio_bytes);

                    pulseIndicator.style.display = "block";

                    audio.play();
                    audio.onended = () => {
                        pulseIndicator.style.display = "none";

                        // Exibe a div novamente quando trigger_record.seconds for 0
                        if (trigger_record.seconds === 0) {
                            startAttendanceDiv.style.display = "flex"; // Exibe a div novamente
                        }

                        record(trigger_record);
                    };

                    // Create an analyser node to get audio data
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const analyser = audioContext.createAnalyser();
                    const source = audioContext.createMediaElementSource(audio);
                    source.connect(analyser);
                    analyser.connect(audioContext.destination);

                    // Set up buffer for frequency data
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);

                    // Function to update animation based on audio volume
                    function updateAnimation() {
                        analyser.getByteFrequencyData(dataArray);

                        // Calculate average volume (loudness) of audio
                        let sum = 0;
                        for (let i = 0; i < bufferLength; i++) {
                            sum += dataArray[i];
                        }
                        const averageVolume = sum / bufferLength;

                        // Scale the pulse animation based on the volume
                        const scale = 1 + (averageVolume / 256); // Scale factor, adjust this to your needs
                        pulseIndicator.style.transform = `translate(-50%, -50%) scale(${scale})`;

                        // Loop the animation
                        requestAnimationFrame(updateAnimation);
                    }

                    updateAnimation();
                }
            })
            .catch(error => console.error("Erro ao processar o áudio:", error));
        }
    </script>

</body>
</html>
